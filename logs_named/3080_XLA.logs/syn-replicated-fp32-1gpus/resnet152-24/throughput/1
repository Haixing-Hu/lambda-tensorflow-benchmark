2020-09-21 07:30:16.698265: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
2020-09-21 07:30:18.106398: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899965000 Hz
2020-09-21 07:30:18.106566: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5173d00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-21 07:30:18.106596: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-21 07:30:18.108968: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-21 07:30:18.227847: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x517c8a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-09-21 07:30:18.227872: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 3080, Compute Capability 8.6
2020-09-21 07:30:18.228676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1634] Found device 0 with properties:
name: GeForce RTX 3080 major: 8 minor: 6 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2020-09-21 07:30:18.228698: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-09-21 07:30:18.231279: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-09-21 07:30:18.232478: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-21 07:30:18.232731: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-21 07:30:18.235597: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-21 07:30:18.236267: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-09-21 07:30:18.236409: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-09-21 07:30:18.237797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1762] Adding visible gpu devices: 0
2020-09-21 07:30:18.237830: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-09-21 07:30:18.458359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1175] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-21 07:30:18.458398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181]      0
2020-09-21 07:30:18.458403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1194] 0:   N
2020-09-21 07:30:18.459367: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-09-21 07:30:18.459391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1320] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9030 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6)
TensorFlow:  1.15
Model:       resnet152
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  24 global
24 per device
Num batches: 500
Num epochs:  0.01
Devices:     ['/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   replicated
AllReduce:   nccl
==========
Generating training model
Initializing graph
2020-09-21 07:30:23.572080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1634] Found device 0 with properties:
name: GeForce RTX 3080 major: 8 minor: 6 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2020-09-21 07:30:23.572116: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-09-21 07:30:23.572140: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-09-21 07:30:23.572149: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-21 07:30:23.572156: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-21 07:30:23.572163: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-21 07:30:23.572170: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-09-21 07:30:23.572178: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-09-21 07:30:23.572916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1762] Adding visible gpu devices: 0
2020-09-21 07:30:23.572941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1175] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-21 07:30:23.572945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181]      0
2020-09-21 07:30:23.572948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1194] 0:   N
2020-09-21 07:30:23.573715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1320] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9030 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6)
2020-09-21 07:30:24.661015: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
INFO:tensorflow:Running local_init_op.
I0921 07:30:24.841764 140132475533120 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I0921 07:30:25.002102 140132475533120 session_manager.py:502] Done running local_init_op.
Running warm up
2020-09-21 07:30:29.165612: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-09-21 07:30:29.636916: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-09-21 07:30:30.665054: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Internal: ptxas exited with non-zero error code 65280, output: ptxas fatal   : Value 'sm_86' is not defined for option 'gpu-name'

Relying on driver to perform ptx compilation. This message will be only logged once.
2020-09-21 07:35:16.180078: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:70] Can't find ptxas binary in ${CUDA_DIR}/bin.  Will back to the GPU driver for PTX -> sass compilation.  This is OK so long as you don't see a warning below about an out-of-date driver version.
2020-09-21 07:35:16.180113: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:71] Searched for CUDA in the following directories:
2020-09-21 07:35:16.180124: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   ./cuda_sdk_lib
2020-09-21 07:35:16.180128: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   /usr/local/cuda
2020-09-21 07:35:16.180133: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   .
2020-09-21 07:35:16.180137: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:76] You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.
2020-09-21 07:35:16.180647: I tensorflow/compiler/jit/xla_compilation_cache.cc:237] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-09-21 07:35:18.078581: W tensorflow/compiler/xla/service/gpu/buffer_comparator.cc:590] Internal: ptxas exited with non-zero error code 65280, output: ptxas fatal   : Value 'sm_86' is not defined for option 'gpu-name'

Relying on driver to perform ptx compilation. This message will be only logged once.
2020-09-21 07:38:53.465691: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:70] Can't find ptxas binary in ${CUDA_DIR}/bin.  Will back to the GPU driver for PTX -> sass compilation.  This is OK so long as you don't see a warning below about an out-of-date driver version.
2020-09-21 07:38:53.465727: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:71] Searched for CUDA in the following directories:
2020-09-21 07:38:53.465736: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   ./cuda_sdk_lib
2020-09-21 07:38:53.465741: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   /usr/local/cuda
2020-09-21 07:38:53.465745: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   .
2020-09-21 07:38:53.465750: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:76] You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.
2020-09-21 07:39:03.880081: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:70] Can't find ptxas binary in ${CUDA_DIR}/bin.  Will back to the GPU driver for PTX -> sass compilation.  This is OK so long as you don't see a warning below about an out-of-date driver version.
2020-09-21 07:39:03.880115: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:71] Searched for CUDA in the following directories:
2020-09-21 07:39:03.880125: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   ./cuda_sdk_lib
2020-09-21 07:39:03.880130: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   /usr/local/cuda
2020-09-21 07:39:03.880134: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   .
2020-09-21 07:39:03.880139: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:76] You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.
Done warm up
Step	Img/sec	total_loss
1	images/sec: 144.2 +/- 0.0 (jitter = 0.0)	9.028 1600673945
10	images/sec: 144.9 +/- 0.2 (jitter = 0.5)	9.032 1600673947
20	images/sec: 144.8 +/- 0.1 (jitter = 0.7)	8.985 1600673949
30	images/sec: 144.6 +/- 0.1 (jitter = 0.6)	8.784 1600673950
40	images/sec: 144.4 +/- 0.1 (jitter = 0.7)	8.971 1600673952
50	images/sec: 144.3 +/- 0.1 (jitter = 0.7)	8.897 1600673954
60	images/sec: 144.2 +/- 0.1 (jitter = 0.7)	9.126 1600673955
70	images/sec: 144.1 +/- 0.1 (jitter = 0.7)	8.851 1600673957
80	images/sec: 144.0 +/- 0.1 (jitter = 0.8)	8.849 1600673959
90	images/sec: 143.8 +/- 0.1 (jitter = 0.9)	9.010 1600673960
100	images/sec: 143.7 +/- 0.1 (jitter = 0.9)	9.019 1600673962
110	images/sec: 143.6 +/- 0.1 (jitter = 0.9)	8.451 1600673964
120	images/sec: 143.6 +/- 0.1 (jitter = 0.9)	9.036 1600673965
130	images/sec: 143.6 +/- 0.1 (jitter = 0.8)	8.707 1600673967
140	images/sec: 143.5 +/- 0.1 (jitter = 0.9)	8.870 1600673969
150	images/sec: 143.4 +/- 0.1 (jitter = 0.9)	8.861 1600673970
160	images/sec: 143.4 +/- 0.1 (jitter = 0.9)	9.017 1600673972
170	images/sec: 143.3 +/- 0.1 (jitter = 0.9)	9.013 1600673974
180	images/sec: 143.3 +/- 0.1 (jitter = 0.9)	9.062 1600673975
190	images/sec: 143.3 +/- 0.1 (jitter = 0.9)	8.745 1600673977
200	images/sec: 143.2 +/- 0.1 (jitter = 0.9)	8.508 1600673979
210	images/sec: 143.2 +/- 0.1 (jitter = 0.9)	9.056 1600673981
220	images/sec: 143.1 +/- 0.1 (jitter = 0.9)	8.906 1600673982
230	images/sec: 143.1 +/- 0.1 (jitter = 1.0)	8.538 1600673984
240	images/sec: 143.1 +/- 0.1 (jitter = 1.0)	8.921 1600673986
250	images/sec: 143.1 +/- 0.1 (jitter = 1.0)	8.861 1600673987
260	images/sec: 143.0 +/- 0.1 (jitter = 1.0)	8.457 1600673989
270	images/sec: 143.0 +/- 0.1 (jitter = 1.0)	8.719 1600673991
280	images/sec: 142.9 +/- 0.1 (jitter = 1.0)	8.680 1600673992
290	images/sec: 142.9 +/- 0.1 (jitter = 1.0)	8.644 1600673994
300	images/sec: 142.8 +/- 0.1 (jitter = 1.0)	9.046 1600673996
310	images/sec: 142.8 +/- 0.1 (jitter = 1.0)	8.680 1600673997
320	images/sec: 142.8 +/- 0.1 (jitter = 1.0)	8.941 1600673999
330	images/sec: 142.7 +/- 0.1 (jitter = 1.0)	8.999 1600674001
340	images/sec: 142.7 +/- 0.1 (jitter = 1.0)	8.867 1600674003
350	images/sec: 142.7 +/- 0.1 (jitter = 1.0)	9.349 1600674004
360	images/sec: 142.6 +/- 0.1 (jitter = 1.0)	8.762 1600674006
370	images/sec: 142.6 +/- 0.1 (jitter = 1.0)	8.941 1600674008
380	images/sec: 142.6 +/- 0.1 (jitter = 1.0)	8.935 1600674009
390	images/sec: 142.6 +/- 0.1 (jitter = 1.0)	9.005 1600674011
400	images/sec: 142.5 +/- 0.1 (jitter = 1.0)	8.902 1600674013
410	images/sec: 142.5 +/- 0.1 (jitter = 1.0)	8.758 1600674014
420	images/sec: 142.5 +/- 0.1 (jitter = 1.0)	8.733 1600674016
430	images/sec: 142.4 +/- 0.1 (jitter = 1.1)	8.602 1600674018
440	images/sec: 142.4 +/- 0.1 (jitter = 1.1)	8.745 1600674020
450	images/sec: 142.4 +/- 0.1 (jitter = 1.1)	8.865 1600674021
460	images/sec: 142.4 +/- 0.1 (jitter = 1.1)	8.915 1600674023
470	images/sec: 142.4 +/- 0.1 (jitter = 1.1)	8.816 1600674025
480	images/sec: 142.3 +/- 0.1 (jitter = 1.1)	8.640 1600674026
490	images/sec: 142.3 +/- 0.1 (jitter = 1.1)	8.357 1600674028
500	images/sec: 142.3 +/- 0.1 (jitter = 1.0)	9.083 1600674030
----------------------------------------------------------------
total images/sec: 142.25
----------------------------------------------------------------
