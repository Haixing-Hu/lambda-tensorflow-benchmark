2020-09-21 07:40:41.612894: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
2020-09-21 07:40:43.030720: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899965000 Hz
2020-09-21 07:40:43.030855: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55af5e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-21 07:40:43.030877: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-21 07:40:43.033203: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-21 07:40:43.114733: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b03e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-09-21 07:40:43.114756: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 3080, Compute Capability 8.6
2020-09-21 07:40:43.115558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1634] Found device 0 with properties:
name: GeForce RTX 3080 major: 8 minor: 6 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2020-09-21 07:40:43.115580: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-09-21 07:40:43.118144: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-09-21 07:40:43.119321: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-21 07:40:43.119576: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-21 07:40:43.122336: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-21 07:40:43.123011: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-09-21 07:40:43.123158: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-09-21 07:40:43.124559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1762] Adding visible gpu devices: 0
2020-09-21 07:40:43.124588: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-09-21 07:40:43.350618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1175] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-21 07:40:43.350660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181]      0
2020-09-21 07:40:43.350665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1194] 0:   N
2020-09-21 07:40:43.351634: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-09-21 07:40:43.351659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1320] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9030 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6)
TensorFlow:  1.15
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  56 global
56 per device
Num batches: 500
Num epochs:  0.02
Devices:     ['/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   replicated
AllReduce:   nccl
==========
Generating training model
Initializing graph
2020-09-21 07:40:45.111972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1634] Found device 0 with properties:
name: GeForce RTX 3080 major: 8 minor: 6 memoryClockRate(GHz): 1.755
pciBusID: 0000:01:00.0
2020-09-21 07:40:45.112008: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-09-21 07:40:45.112029: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-09-21 07:40:45.112037: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-21 07:40:45.112043: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-21 07:40:45.112050: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-21 07:40:45.112056: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-09-21 07:40:45.112063: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-09-21 07:40:45.112810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1762] Adding visible gpu devices: 0
2020-09-21 07:40:45.112836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1175] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-21 07:40:45.112840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181]      0
2020-09-21 07:40:45.112844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1194] 0:   N
2020-09-21 07:40:45.113615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1320] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9030 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6)
2020-09-21 07:40:45.416854: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
INFO:tensorflow:Running local_init_op.
I0921 07:40:45.464248 139675871643456 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I0921 07:40:45.512922 139675871643456 session_manager.py:502] Done running local_init_op.
Running warm up
2020-09-21 07:40:46.623314: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-09-21 07:40:47.108774: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-09-21 07:40:48.105633: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Internal: ptxas exited with non-zero error code 65280, output: ptxas fatal   : Value 'sm_86' is not defined for option 'gpu-name'

Relying on driver to perform ptx compilation. This message will be only logged once.
2020-09-21 07:45:36.674884: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:70] Can't find ptxas binary in ${CUDA_DIR}/bin.  Will back to the GPU driver for PTX -> sass compilation.  This is OK so long as you don't see a warning below about an out-of-date driver version.
2020-09-21 07:45:36.674918: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:71] Searched for CUDA in the following directories:
2020-09-21 07:45:36.674927: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   ./cuda_sdk_lib
2020-09-21 07:45:36.674931: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   /usr/local/cuda
2020-09-21 07:45:36.674935: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   .
2020-09-21 07:45:36.674940: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:76] You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.
2020-09-21 07:45:36.675488: I tensorflow/compiler/jit/xla_compilation_cache.cc:237] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-09-21 07:45:37.578372: W tensorflow/compiler/xla/service/gpu/buffer_comparator.cc:590] Internal: ptxas exited with non-zero error code 65280, output: ptxas fatal   : Value 'sm_86' is not defined for option 'gpu-name'

Relying on driver to perform ptx compilation. This message will be only logged once.
2020-09-21 07:48:53.539226: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:70] Can't find ptxas binary in ${CUDA_DIR}/bin.  Will back to the GPU driver for PTX -> sass compilation.  This is OK so long as you don't see a warning below about an out-of-date driver version.
2020-09-21 07:48:53.539262: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:71] Searched for CUDA in the following directories:
2020-09-21 07:48:53.539272: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   ./cuda_sdk_lib
2020-09-21 07:48:53.539276: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   /usr/local/cuda
2020-09-21 07:48:53.539281: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   .
2020-09-21 07:48:53.539285: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:76] You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.
2020-09-21 07:48:56.331964: W tensorflow/core/common_runtime/bfc_allocator.cc:305] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.
2020-09-21 07:48:57.539426: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:70] Can't find ptxas binary in ${CUDA_DIR}/bin.  Will back to the GPU driver for PTX -> sass compilation.  This is OK so long as you don't see a warning below about an out-of-date driver version.
2020-09-21 07:48:57.539461: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:71] Searched for CUDA in the following directories:
2020-09-21 07:48:57.539470: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   ./cuda_sdk_lib
2020-09-21 07:48:57.539475: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   /usr/local/cuda
2020-09-21 07:48:57.539479: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   .
2020-09-21 07:48:57.539484: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:76] You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.
Done warm up
Step	Img/sec	total_loss
1	images/sec: 424.2 +/- 0.0 (jitter = 0.0)	8.009 1600674538
10	images/sec: 424.0 +/- 0.3 (jitter = 1.5)	7.830 1600674540
20	images/sec: 424.9 +/- 0.3 (jitter = 1.2)	7.858 1600674541
30	images/sec: 424.6 +/- 0.2 (jitter = 1.6)	7.919 1600674542
40	images/sec: 424.3 +/- 0.2 (jitter = 1.6)	7.754 1600674544
50	images/sec: 424.1 +/- 0.2 (jitter = 1.6)	8.036 1600674545
60	images/sec: 424.0 +/- 0.2 (jitter = 1.4)	7.909 1600674546
70	images/sec: 424.1 +/- 0.2 (jitter = 1.6)	7.717 1600674548
80	images/sec: 424.0 +/- 0.2 (jitter = 1.6)	7.865 1600674549
90	images/sec: 423.9 +/- 0.2 (jitter = 1.8)	7.936 1600674550
100	images/sec: 423.8 +/- 0.2 (jitter = 1.8)	7.834 1600674552
110	images/sec: 423.7 +/- 0.1 (jitter = 1.8)	7.639 1600674553
120	images/sec: 423.6 +/- 0.1 (jitter = 1.7)	7.791 1600674554
130	images/sec: 423.6 +/- 0.1 (jitter = 1.6)	7.930 1600674555
140	images/sec: 423.5 +/- 0.1 (jitter = 1.6)	7.934 1600674557
150	images/sec: 423.4 +/- 0.1 (jitter = 1.6)	7.875 1600674558
160	images/sec: 423.4 +/- 0.1 (jitter = 1.6)	7.838 1600674559
170	images/sec: 423.3 +/- 0.1 (jitter = 1.6)	7.716 1600674561
180	images/sec: 423.2 +/- 0.1 (jitter = 1.6)	7.815 1600674562
190	images/sec: 423.2 +/- 0.1 (jitter = 1.5)	7.855 1600674563
200	images/sec: 423.1 +/- 0.1 (jitter = 1.6)	8.054 1600674565
210	images/sec: 423.0 +/- 0.1 (jitter = 1.7)	7.737 1600674566
220	images/sec: 422.9 +/- 0.1 (jitter = 1.7)	7.829 1600674567
230	images/sec: 422.8 +/- 0.1 (jitter = 1.7)	7.883 1600674569
240	images/sec: 422.7 +/- 0.1 (jitter = 1.9)	7.776 1600674570
250	images/sec: 422.6 +/- 0.1 (jitter = 1.9)	7.852 1600674571
260	images/sec: 422.6 +/- 0.1 (jitter = 1.9)	7.953 1600674573
270	images/sec: 422.5 +/- 0.1 (jitter = 2.0)	7.851 1600674574
280	images/sec: 422.5 +/- 0.1 (jitter = 2.1)	7.761 1600674575
290	images/sec: 422.3 +/- 0.1 (jitter = 2.1)	7.721 1600674577
300	images/sec: 422.3 +/- 0.1 (jitter = 2.1)	7.668 1600674578
310	images/sec: 422.2 +/- 0.1 (jitter = 2.1)	8.020 1600674579
320	images/sec: 422.2 +/- 0.1 (jitter = 2.1)	7.813 1600674581
330	images/sec: 422.1 +/- 0.1 (jitter = 2.0)	7.936 1600674582
340	images/sec: 422.1 +/- 0.1 (jitter = 2.0)	7.928 1600674583
350	images/sec: 422.0 +/- 0.1 (jitter = 2.1)	7.758 1600674585
360	images/sec: 422.0 +/- 0.1 (jitter = 2.1)	7.808 1600674586
370	images/sec: 421.9 +/- 0.1 (jitter = 2.2)	7.942 1600674587
380	images/sec: 421.9 +/- 0.1 (jitter = 2.2)	7.787 1600674589
390	images/sec: 421.8 +/- 0.1 (jitter = 2.2)	7.842 1600674590
400	images/sec: 421.8 +/- 0.1 (jitter = 2.1)	7.763 1600674591
410	images/sec: 421.8 +/- 0.1 (jitter = 2.2)	7.855 1600674593
420	images/sec: 421.7 +/- 0.1 (jitter = 2.1)	7.732 1600674594
430	images/sec: 421.7 +/- 0.1 (jitter = 2.2)	7.689 1600674595
440	images/sec: 421.6 +/- 0.1 (jitter = 2.2)	7.585 1600674597
450	images/sec: 421.6 +/- 0.1 (jitter = 2.2)	7.587 1600674598
460	images/sec: 421.5 +/- 0.1 (jitter = 2.2)	7.904 1600674599
470	images/sec: 421.5 +/- 0.1 (jitter = 2.2)	7.910 1600674601
480	images/sec: 421.4 +/- 0.1 (jitter = 2.2)	7.793 1600674602
490	images/sec: 421.3 +/- 0.1 (jitter = 2.3)	7.816 1600674603
500	images/sec: 421.3 +/- 0.1 (jitter = 2.3)	7.989 1600674605
----------------------------------------------------------------
total images/sec: 421.13
----------------------------------------------------------------
