2020-12-31 23:35:00.595918: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
2020-12-31 23:35:02.453580: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2500090000 Hz
2020-12-31 23:35:02.453805: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5d6a910 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-31 23:35:02.453831: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-31 23:35:02.456234: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2020-12-31 23:35:05.715615: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5d6b710 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-31 23:35:05.715664: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): RTX A6000, Compute Capability 8.6
2020-12-31 23:35:05.715674: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): RTX A6000, Compute Capability 8.6
2020-12-31 23:35:05.721589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1665] Found device 0 with properties:
name: RTX A6000 major: 8 minor: 6 memoryClockRate(GHz): 1.8
pciBusID: 0000:01:00.0
2020-12-31 23:35:05.725825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1665] Found device 1 with properties:
name: RTX A6000 major: 8 minor: 6 memoryClockRate(GHz): 1.8
pciBusID: 0000:25:00.0
2020-12-31 23:35:05.725862: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2020-12-31 23:35:05.728297: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2020-12-31 23:35:05.729177: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2020-12-31 23:35:05.729382: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2020-12-31 23:35:05.731988: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2020-12-31 23:35:05.732490: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2020-12-31 23:35:05.732614: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2020-12-31 23:35:05.741780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1793] Adding visible gpu devices: 0, 1
2020-12-31 23:35:05.741813: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2020-12-31 23:35:09.183707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1206] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-31 23:35:09.183766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212]      0 1
2020-12-31 23:35:09.183773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1225] 0:   N Y
2020-12-31 23:35:09.183776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1225] 1:   Y N
2020-12-31 23:35:09.191027: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-12-31 23:35:09.191065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1351] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 46776 MB memory) -> physical GPU (device: 0, name: RTX A6000, pci bus id: 0000:01:00.0, compute capability: 8.6)
2020-12-31 23:35:09.194193: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-12-31 23:35:09.194213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1351] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 46776 MB memory) -> physical GPU (device: 1, name: RTX A6000, pci bus id: 0000:25:00.0, compute capability: 8.6)
TensorFlow:  1.15
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  1024 global
512 per device
Num batches: 100
Num epochs:  0.08
Devices:     ['/gpu:0', '/gpu:1']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   replicated
AllReduce:   nccl
==========
Generating training model
Initializing graph
2020-12-31 23:35:14.261038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1665] Found device 0 with properties:
name: RTX A6000 major: 8 minor: 6 memoryClockRate(GHz): 1.8
pciBusID: 0000:01:00.0
2020-12-31 23:35:14.267585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1665] Found device 1 with properties:
name: RTX A6000 major: 8 minor: 6 memoryClockRate(GHz): 1.8
pciBusID: 0000:25:00.0
2020-12-31 23:35:14.267631: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2020-12-31 23:35:14.267669: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2020-12-31 23:35:14.267683: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2020-12-31 23:35:14.267694: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2020-12-31 23:35:14.267706: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2020-12-31 23:35:14.267717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2020-12-31 23:35:14.267729: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2020-12-31 23:35:14.287441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1793] Adding visible gpu devices: 0, 1
2020-12-31 23:35:14.287508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1206] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-31 23:35:14.287516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212]      0 1
2020-12-31 23:35:14.287522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1225] 0:   N Y
2020-12-31 23:35:14.287527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1225] 1:   Y N
2020-12-31 23:35:14.297871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1351] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 46776 MB memory) -> physical GPU (device: 0, name: RTX A6000, pci bus id: 0000:01:00.0, compute capability: 8.6)
2020-12-31 23:35:14.300298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1351] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 46776 MB memory) -> physical GPU (device: 1, name: RTX A6000, pci bus id: 0000:25:00.0, compute capability: 8.6)
2020-12-31 23:35:16.653909: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
INFO:tensorflow:Running local_init_op.
I1231 23:35:19.408886 140011414755136 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1231 23:35:21.136071 140011414755136 session_manager.py:502] Done running local_init_op.
Running warm up
2020-12-31 23:35:26.279008: I tensorflow/core/grappler/optimizers/generic_layout_optimizer.cc:345] Cancel Transpose nodes around Pad: transpose_before=tower_0/v0/transpose pad=tower_0/v0/cg/conv0/Pad transpose_after=tower_0/v0/cg/conv0/conv2d/Conv2D-0-TransposeNCHWToNHWC-LayoutOptimizer,tower_0/v0/gradients/tower_0/v0/cg/conv0/conv2d/Conv2D_grad/Conv2DBackpropFilter-0-TransposeNCHWToNHWC-LayoutOptimizer
2020-12-31 23:35:26.279330: I tensorflow/core/grappler/optimizers/generic_layout_optimizer.cc:345] Cancel Transpose nodes around Pad: transpose_before=tower_1/v1/transpose pad=tower_1/v1/cg/conv0/Pad transpose_after=tower_1/v1/cg/conv0/conv2d/Conv2D-0-TransposeNCHWToNHWC-LayoutOptimizer,tower_1/v1/gradients/tower_1/v1/cg/conv0/conv2d/Conv2D_grad/Conv2DBackpropFilter-0-TransposeNCHWToNHWC-LayoutOptimizer
2020-12-31 23:35:28.103417: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2020-12-31 23:35:33.194882: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2020-12-31 23:36:07.842778: I tensorflow/compiler/jit/xla_compilation_cache.cc:241] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-12-31 23:36:33.515646: W tensorflow/core/common_runtime/bfc_allocator.cc:305] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.
Done warm up
Step	Img/sec	total_loss
1	images/sec: 2803.1 +/- 0.0 (jitter = 0.0)	7.942 1609457814
10	images/sec: 2809.4 +/- 1.2 (jitter = 4.0)	7.849 1609457818
20	images/sec: 2810.1 +/- 0.9 (jitter = 4.4)	7.746 1609457821
30	images/sec: 2808.6 +/- 1.2 (jitter = 4.9)	7.747 1609457825
40	images/sec: 2807.8 +/- 1.1 (jitter = 5.3)	7.702 1609457829
50	images/sec: 2805.0 +/- 1.3 (jitter = 7.9)	7.680 1609457832
60	images/sec: 2803.4 +/- 1.3 (jitter = 8.3)	7.669 1609457836
70	images/sec: 2802.9 +/- 1.1 (jitter = 8.1)	7.589 1609457840
80	images/sec: 2801.5 +/- 1.1 (jitter = 10.2)	7.609 1609457843
90	images/sec: 2800.3 +/- 1.0 (jitter = 10.6)	7.555 1609457847
100	images/sec: 2799.2 +/- 1.0 (jitter = 10.8)	7.538 1609457851
----------------------------------------------------------------
total images/sec: 2798.66
----------------------------------------------------------------
