2020-12-31 23:31:23.660990: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
2020-12-31 23:31:25.513649: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2500090000 Hz
2020-12-31 23:31:25.513853: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5be5c40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-31 23:31:25.513878: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-31 23:31:25.516083: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2020-12-31 23:31:28.882473: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5bee810 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-31 23:31:28.882528: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): RTX A6000, Compute Capability 8.6
2020-12-31 23:31:28.882539: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): RTX A6000, Compute Capability 8.6
2020-12-31 23:31:28.888622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1665] Found device 0 with properties:
name: RTX A6000 major: 8 minor: 6 memoryClockRate(GHz): 1.8
pciBusID: 0000:01:00.0
2020-12-31 23:31:28.892923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1665] Found device 1 with properties:
name: RTX A6000 major: 8 minor: 6 memoryClockRate(GHz): 1.8
pciBusID: 0000:25:00.0
2020-12-31 23:31:28.892964: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2020-12-31 23:31:28.895875: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2020-12-31 23:31:28.896717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2020-12-31 23:31:28.896909: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2020-12-31 23:31:28.899463: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2020-12-31 23:31:28.899958: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2020-12-31 23:31:28.900069: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2020-12-31 23:31:28.909259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1793] Adding visible gpu devices: 0, 1
2020-12-31 23:31:28.909298: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2020-12-31 23:31:32.287037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1206] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-31 23:31:32.287094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212]      0 1
2020-12-31 23:31:32.287101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1225] 0:   N Y
2020-12-31 23:31:32.287104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1225] 1:   Y N
2020-12-31 23:31:32.294343: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-12-31 23:31:32.294383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1351] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 46776 MB memory) -> physical GPU (device: 0, name: RTX A6000, pci bus id: 0000:01:00.0, compute capability: 8.6)
2020-12-31 23:31:32.297608: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-12-31 23:31:32.297628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1351] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 46776 MB memory) -> physical GPU (device: 1, name: RTX A6000, pci bus id: 0000:25:00.0, compute capability: 8.6)
TensorFlow:  1.15
Model:       resnet152
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  512 global
256 per device
Num batches: 100
Num epochs:  0.04
Devices:     ['/gpu:0', '/gpu:1']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   replicated
AllReduce:   nccl
==========
Generating training model
Initializing graph
2020-12-31 23:31:47.578245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1665] Found device 0 with properties:
name: RTX A6000 major: 8 minor: 6 memoryClockRate(GHz): 1.8
pciBusID: 0000:01:00.0
2020-12-31 23:31:47.586768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1665] Found device 1 with properties:
name: RTX A6000 major: 8 minor: 6 memoryClockRate(GHz): 1.8
pciBusID: 0000:25:00.0
2020-12-31 23:31:47.586831: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2020-12-31 23:31:47.586909: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2020-12-31 23:31:47.586922: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2020-12-31 23:31:47.586936: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2020-12-31 23:31:47.586948: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2020-12-31 23:31:47.586959: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2020-12-31 23:31:47.586971: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2020-12-31 23:31:47.605150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1793] Adding visible gpu devices: 0, 1
2020-12-31 23:31:47.605226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1206] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-31 23:31:47.605235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212]      0 1
2020-12-31 23:31:47.605241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1225] 0:   N Y
2020-12-31 23:31:47.605246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1225] 1:   Y N
2020-12-31 23:31:47.616337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1351] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 46776 MB memory) -> physical GPU (device: 0, name: RTX A6000, pci bus id: 0000:01:00.0, compute capability: 8.6)
2020-12-31 23:31:47.619781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1351] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 46776 MB memory) -> physical GPU (device: 1, name: RTX A6000, pci bus id: 0000:25:00.0, compute capability: 8.6)
2020-12-31 23:31:51.879252: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
INFO:tensorflow:Running local_init_op.
I1231 23:31:54.439063 140483946542912 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1231 23:31:55.940385 140483946542912 session_manager.py:502] Done running local_init_op.
Running warm up
2020-12-31 23:32:08.085747: I tensorflow/core/grappler/optimizers/generic_layout_optimizer.cc:345] Cancel Transpose nodes around Pad: transpose_before=tower_0/v0/transpose pad=tower_0/v0/cg/conv0/Pad transpose_after=tower_0/v0/cg/conv0/conv2d/Conv2D-0-TransposeNCHWToNHWC-LayoutOptimizer,tower_0/v0/gradients/tower_0/v0/cg/conv0/conv2d/Conv2D_grad/Conv2DBackpropFilter-0-TransposeNCHWToNHWC-LayoutOptimizer
2020-12-31 23:32:08.085898: I tensorflow/core/grappler/optimizers/generic_layout_optimizer.cc:345] Cancel Transpose nodes around Pad: transpose_before=tower_1/v1/transpose pad=tower_1/v1/cg/conv0/Pad transpose_after=tower_1/v1/cg/conv0/conv2d/Conv2D-0-TransposeNCHWToNHWC-LayoutOptimizer,tower_1/v1/gradients/tower_1/v1/cg/conv0/conv2d/Conv2D_grad/Conv2DBackpropFilter-0-TransposeNCHWToNHWC-LayoutOptimizer
2020-12-31 23:32:13.733346: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2020-12-31 23:32:18.457023: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2020-12-31 23:32:47.280361: I tensorflow/compiler/jit/xla_compilation_cache.cc:241] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-12-31 23:33:27.202678: W tensorflow/core/common_runtime/bfc_allocator.cc:305] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.
Done warm up
Step	Img/sec	total_loss
1	images/sec: 1196.4 +/- 0.0 (jitter = 0.0)	8.826 1609457634
10	images/sec: 1197.0 +/- 0.9 (jitter = 2.7)	8.801 1609457637
20	images/sec: 1196.5 +/- 0.6 (jitter = 1.7)	8.890 1609457642
30	images/sec: 1191.6 +/- 1.4 (jitter = 3.9)	8.877 1609457646
40	images/sec: 1189.2 +/- 1.3 (jitter = 10.2)	8.899 1609457650
50	images/sec: 1187.4 +/- 1.1 (jitter = 9.6)	8.796 1609457655
60	images/sec: 1185.3 +/- 1.1 (jitter = 8.5)	8.834 1609457659
70	images/sec: 1184.4 +/- 1.0 (jitter = 6.5)	8.806 1609457663
80	images/sec: 1183.5 +/- 1.0 (jitter = 6.3)	8.799 1609457668
90	images/sec: 1182.7 +/- 0.9 (jitter = 6.4)	8.717 1609457672
100	images/sec: 1182.2 +/- 0.8 (jitter = 6.3)	8.665 1609457677
----------------------------------------------------------------
total images/sec: 1181.99
----------------------------------------------------------------
