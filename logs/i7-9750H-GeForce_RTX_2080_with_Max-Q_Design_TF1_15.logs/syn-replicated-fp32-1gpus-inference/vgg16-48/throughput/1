2020-07-10 08:52:11.386532: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-07-10 08:52:11.391844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
WARNING:tensorflow:From /usr/lib/python3/dist-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
2020-07-10 08:52:12.819915: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599990000 Hz
2020-07-10 08:52:12.820074: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3016990 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-07-10 08:52:12.820089: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-07-10 08:52:12.821720: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-07-10 08:52:12.892933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-10 08:52:12.893369: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4dadf10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-07-10 08:52:12.893382: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 with Max-Q Design, Compute Capability 7.5
2020-07-10 08:52:12.893517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-10 08:52:12.893987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: GeForce RTX 2080 with Max-Q Design major: 7 minor: 5 memoryClockRate(GHz): 1.095
pciBusID: 0000:01:00.0
2020-07-10 08:52:12.894023: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-07-10 08:52:12.895053: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-07-10 08:52:12.895902: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-07-10 08:52:12.896149: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-07-10 08:52:12.897152: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-07-10 08:52:12.897952: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-07-10 08:52:12.900344: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-10 08:52:12.900437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-10 08:52:12.901225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-10 08:52:12.902597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2020-07-10 08:52:13.233162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-10 08:52:13.233188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0
2020-07-10 08:52:13.233193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N
2020-07-10 08:52:13.233333: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-10 08:52:13.233671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-10 08:52:13.233961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7077 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5)
TensorFlow:  1.15
Model:       vgg16
Dataset:     imagenet (synthetic)
Mode:        forward only
SingleSess:  False
Batch size:  48 global
48 per device
Num batches: 100
Num epochs:  0.00
Devices:     ['/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   replicated
AllReduce:   nccl
==========
Generating training model
WARNING:tensorflow:From /home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py:134: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0710 08:52:13.246151 140074989942592 deprecation.py:323] From /home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py:134: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
WARNING:tensorflow:From /usr/lib/python3/dist-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
W0710 08:52:13.246946 140074989942592 deprecation.py:323] From /usr/lib/python3/dist-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING:tensorflow:From /home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py:266: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.MaxPooling2D instead.
W0710 08:52:13.267306 140074989942592 deprecation.py:323] From /home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py:266: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.MaxPooling2D instead.
WARNING:tensorflow:From /home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py:408: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dropout instead.
W0710 08:52:13.381082 140074989942592 deprecation.py:323] From /home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py:408: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dropout instead.
Initializing graph
WARNING:tensorflow:From /home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py:2269: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
W0710 08:52:13.430599 140074989942592 deprecation.py:323] From /home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py:2269: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
WARNING:tensorflow:From /usr/lib/python3/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0710 08:52:13.452514 140074989942592 deprecation.py:323] From /usr/lib/python3/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2020-07-10 08:52:13.465326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-10 08:52:13.465657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: GeForce RTX 2080 with Max-Q Design major: 7 minor: 5 memoryClockRate(GHz): 1.095
pciBusID: 0000:01:00.0
2020-07-10 08:52:13.465676: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-07-10 08:52:13.465697: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-07-10 08:52:13.465707: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-07-10 08:52:13.465716: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-07-10 08:52:13.465725: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-07-10 08:52:13.465734: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-07-10 08:52:13.465743: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-10 08:52:13.465784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-10 08:52:13.466105: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-10 08:52:13.466375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2020-07-10 08:52:13.466393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-10 08:52:13.466397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0
2020-07-10 08:52:13.466401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N
2020-07-10 08:52:13.466455: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-10 08:52:13.466756: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-10 08:52:13.467037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7077 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5)
INFO:tensorflow:Running local_init_op.
I0710 08:52:13.535923 140074989942592 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I0710 08:52:13.557904 140074989942592 session_manager.py:502] Done running local_init_op.
Running warm up
2020-07-10 08:52:13.637397: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-07-10 08:52:13.794624: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-10 08:52:14.641987: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 2.85G (3058420736 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:15.004912: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-07-10 08:52:15.004936: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-07-10 08:52:15.127001: W tensorflow/core/common_runtime/bfc_allocator.cc:305] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.
2020-07-10 08:52:15.207093: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 2.85G (3058420736 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:15.207143: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.60GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-07-10 08:52:15.207932: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 2.85G (3058420736 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:15.207953: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.60GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-07-10 08:52:15.632898: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 2.85G (3058420736 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:15.632935: W tensorflow/core/common_runtime/bfc_allocator.cc:305] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.
2020-07-10 08:52:15.693910: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 4.85G (5205904384 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:15.693951: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.60GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-07-10 08:52:15.694604: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 4.85G (5205904384 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:15.694619: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.60GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-07-10 08:52:15.695254: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 4.85G (5205904384 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:15.695268: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.81GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-07-10 08:52:15.695889: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 4.85G (5205904384 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:15.695902: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.81GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-07-10 08:52:15.771901: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 4.85G (5205904384 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:15.771920: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.31GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-07-10 08:52:15.772429: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 4.85G (5205904384 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:15.772439: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.31GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-07-10 08:52:15.898868: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 4.85G (5205904384 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:15.899376: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 4.85G (5205904384 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:16.086850: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 4.85G (5205904384 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:16.087323: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 4.85G (5205904384 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:16.087880: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 4.85G (5205904384 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:16.088533: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 4.85G (5205904384 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:16.316399: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 4.85G (5205904384 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:16.316439: W tensorflow/core/common_runtime/bfc_allocator.cc:305] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.
2020-07-10 08:52:16.357051: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 5.85G (6279646208 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:16.357727: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 5.85G (6279646208 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:16.376974: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 5.85G (6279646208 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:16.377756: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 5.85G (6279646208 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:16.378530: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 5.85G (6279646208 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:16.379304: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 5.85G (6279646208 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:16.505939: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 5.85G (6279646208 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:16.506542: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 5.85G (6279646208 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:16.507145: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 5.85G (6279646208 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:16.507743: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 5.85G (6279646208 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:16.558531: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 5.85G (6279646208 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:16.559257: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 5.85G (6279646208 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:16.560002: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 5.85G (6279646208 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:16.560851: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 5.85G (6279646208 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:16.665223: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 5.85G (6279646208 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:16.665905: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 5.85G (6279646208 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:16.681764: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 5.85G (6279646208 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:16.682497: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 5.85G (6279646208 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:16.704302: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 5.85G (6279646208 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:16.704898: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 5.85G (6279646208 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:26.705638: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 5.85G (6279646208 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:26.706279: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 5.85G (6279646208 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-10 08:52:26.706296: W tensorflow/core/common_runtime/bfc_allocator.cc:419] Allocator (GPU_0_bfc) ran out of memory trying to allocate 588.00MiB (rounded to 616562688).  Current allocation summary follows.
2020-07-10 08:52:26.706305: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (256): 	Total Chunks: 26, Chunks in use: 26. 6.5KiB allocated for chunks. 6.5KiB in use in bin. 1.3KiB client-requested in use in bin.
2020-07-10 08:52:26.706310: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (512): 	Total Chunks: 4, Chunks in use: 4. 2.0KiB allocated for chunks. 2.0KiB in use in bin. 2.0KiB client-requested in use in bin.
2020-07-10 08:52:26.706314: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (1024): 	Total Chunks: 7, Chunks in use: 7. 7.2KiB allocated for chunks. 7.2KiB in use in bin. 7.0KiB client-requested in use in bin.
2020-07-10 08:52:26.706319: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (2048): 	Total Chunks: 12, Chunks in use: 12. 24.0KiB allocated for chunks. 24.0KiB in use in bin. 24.0KiB client-requested in use in bin.
2020-07-10 08:52:26.706324: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (4096): 	Total Chunks: 3, Chunks in use: 3. 14.8KiB allocated for chunks. 14.8KiB in use in bin. 14.6KiB client-requested in use in bin.
2020-07-10 08:52:26.706328: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-07-10 08:52:26.706333: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (16384): 	Total Chunks: 4, Chunks in use: 4. 64.0KiB allocated for chunks. 64.0KiB in use in bin. 64.0KiB client-requested in use in bin.
2020-07-10 08:52:26.706337: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (32768): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-07-10 08:52:26.706341: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (65536): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-07-10 08:52:26.706346: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (131072): 	Total Chunks: 1, Chunks in use: 1. 144.0KiB allocated for chunks. 144.0KiB in use in bin. 144.0KiB client-requested in use in bin.
2020-07-10 08:52:26.706351: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (262144): 	Total Chunks: 1, Chunks in use: 1. 288.0KiB allocated for chunks. 288.0KiB in use in bin. 288.0KiB client-requested in use in bin.
2020-07-10 08:52:26.706356: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (524288): 	Total Chunks: 1, Chunks in use: 1. 964.2KiB allocated for chunks. 964.2KiB in use in bin. 576.0KiB client-requested in use in bin.
2020-07-10 08:52:26.706361: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (1048576): 	Total Chunks: 1, Chunks in use: 1. 1.12MiB allocated for chunks. 1.12MiB in use in bin. 1.12MiB client-requested in use in bin.
2020-07-10 08:52:26.706365: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (2097152): 	Total Chunks: 2, Chunks in use: 2. 4.50MiB allocated for chunks. 4.50MiB in use in bin. 4.50MiB client-requested in use in bin.
2020-07-10 08:52:26.706369: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-07-10 08:52:26.706374: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (8388608): 	Total Chunks: 5, Chunks in use: 5. 50.68MiB allocated for chunks. 50.68MiB in use in bin. 47.14MiB client-requested in use in bin.
2020-07-10 08:52:26.706379: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (16777216): 	Total Chunks: 4, Chunks in use: 4. 87.12MiB allocated for chunks. 87.12MiB in use in bin. 73.12MiB client-requested in use in bin.
2020-07-10 08:52:26.706384: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-07-10 08:52:26.706388: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (67108864): 	Total Chunks: 1, Chunks in use: 1. 64.00MiB allocated for chunks. 64.00MiB in use in bin. 64.00MiB client-requested in use in bin.
2020-07-10 08:52:26.706392: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-07-10 08:52:26.706397: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (268435456): 	Total Chunks: 2, Chunks in use: 1. 880.09MiB allocated for chunks. 512.00MiB in use in bin. 392.00MiB client-requested in use in bin.
2020-07-10 08:52:26.706402: I tensorflow/core/common_runtime/bfc_allocator.cc:885] Bin for 588.00MiB was 256.00MiB, Chunk State:
2020-07-10 08:52:26.706409: I tensorflow/core/common_runtime/bfc_allocator.cc:891]   Size: 368.09MiB | Requested Size: 48B | in_use: 0 | bin_num: 20, prev:   Size: 27.56MiB | Requested Size: 27.56MiB | in_use: 1 | bin_num: -1
2020-07-10 08:52:26.706413: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 536870912
2020-07-10 08:52:26.706418: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f6434000000 next 59 of size 16400384
2020-07-10 08:52:26.706422: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f6434fa4000 next 61 of size 67108864
2020-07-10 08:52:26.706426: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f6438fa4000 next 62 of size 147456
2020-07-10 08:52:26.706430: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f6438fc8000 next 63 of size 9437184
2020-07-10 08:52:26.706433: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64398c8000 next 64 of size 2048
2020-07-10 08:52:26.706436: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64398c8800 next 65 of size 2048
2020-07-10 08:52:26.706439: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64398c9000 next 66 of size 256
2020-07-10 08:52:26.706443: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64398c9100 next 67 of size 256
2020-07-10 08:52:26.706446: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64398c9200 next 68 of size 28901376
2020-07-10 08:52:26.706449: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f643b459200 next 69 of size 256
2020-07-10 08:52:26.706452: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f643b459300 next 70 of size 256
2020-07-10 08:52:26.706457: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f643b459400 next 71 of size 256
2020-07-10 08:52:26.706462: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f643b459500 next 72 of size 256
2020-07-10 08:52:26.706468: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f643b459600 next 76 of size 28901376
2020-07-10 08:52:26.706474: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0x7f643cfe9600 next 18446744073709551615 of size 385968640
2020-07-10 08:52:26.706479: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 536870912
2020-07-10 08:52:26.706482: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f6454000000 next 18446744073709551615 of size 536870912
2020-07-10 08:52:26.706485: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 33554432
2020-07-10 08:52:26.706489: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f6474000000 next 39 of size 1179648
2020-07-10 08:52:26.706492: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f6474120000 next 40 of size 512
2020-07-10 08:52:26.706497: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f6474120200 next 41 of size 9437184
2020-07-10 08:52:26.706500: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f6474a20200 next 42 of size 256
2020-07-10 08:52:26.706503: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f6474a20300 next 43 of size 294912
2020-07-10 08:52:26.706507: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f6474a68300 next 44 of size 6912
2020-07-10 08:52:26.706510: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f6474a69e00 next 46 of size 16384
2020-07-10 08:52:26.706514: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f6474a6de00 next 47 of size 9437184
2020-07-10 08:52:26.706517: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f647536de00 next 48 of size 2048
2020-07-10 08:52:26.706520: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f647536e600 next 49 of size 2359296
2020-07-10 08:52:26.706523: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64755ae600 next 50 of size 512
2020-07-10 08:52:26.706527: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64755ae800 next 51 of size 2048
2020-07-10 08:52:26.706530: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64755af000 next 52 of size 4096
2020-07-10 08:52:26.706533: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64755b0000 next 53 of size 2048
2020-07-10 08:52:26.706536: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64755b0800 next 54 of size 256
2020-07-10 08:52:26.706540: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64755b0900 next 55 of size 1024
2020-07-10 08:52:26.706543: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64755b0d00 next 56 of size 2359296
2020-07-10 08:52:26.706546: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64757f0d00 next 57 of size 16384
2020-07-10 08:52:26.706549: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64757f4d00 next 60 of size 2048
2020-07-10 08:52:26.706553: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64757f5500 next 18446744073709551615 of size 8432384
2020-07-10 08:52:26.706556: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 16777216
2020-07-10 08:52:26.706559: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f6476000000 next 18446744073709551615 of size 16777216
2020-07-10 08:52:26.706563: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 16777216
2020-07-10 08:52:26.706566: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f6477000000 next 18446744073709551615 of size 16777216
2020-07-10 08:52:26.706569: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 1048576
2020-07-10 08:52:26.706572: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b9400000 next 1 of size 4096
2020-07-10 08:52:26.706575: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b9401000 next 2 of size 2048
2020-07-10 08:52:26.706579: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b9401800 next 3 of size 256
2020-07-10 08:52:26.706582: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b9401900 next 4 of size 256
2020-07-10 08:52:26.706585: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b9401a00 next 5 of size 256
2020-07-10 08:52:26.706588: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b9401b00 next 6 of size 256
2020-07-10 08:52:26.706591: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b9401c00 next 7 of size 2048
2020-07-10 08:52:26.706594: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b9402400 next 8 of size 256
2020-07-10 08:52:26.706599: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b9402500 next 9 of size 256
2020-07-10 08:52:26.706605: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b9402600 next 10 of size 256
2020-07-10 08:52:26.706611: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b9402700 next 11 of size 256
2020-07-10 08:52:26.706616: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b9402800 next 12 of size 256
2020-07-10 08:52:26.706620: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b9402900 next 13 of size 512
2020-07-10 08:52:26.706623: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b9402b00 next 14 of size 16384
2020-07-10 08:52:26.706626: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b9406b00 next 15 of size 256
2020-07-10 08:52:26.706630: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b9406c00 next 16 of size 2048
2020-07-10 08:52:26.706633: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b9407400 next 17 of size 512
2020-07-10 08:52:26.706636: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b9407600 next 18 of size 256
2020-07-10 08:52:26.706639: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b9407700 next 19 of size 256
2020-07-10 08:52:26.706643: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b9407800 next 20 of size 1024
2020-07-10 08:52:26.706646: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b9407c00 next 21 of size 256
2020-07-10 08:52:26.706649: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b9407d00 next 22 of size 256
2020-07-10 08:52:26.706652: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b9407e00 next 23 of size 1024
2020-07-10 08:52:26.706656: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b9408200 next 24 of size 2048
2020-07-10 08:52:26.706659: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b9408a00 next 25 of size 256
2020-07-10 08:52:26.706662: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b9408b00 next 26 of size 1024
2020-07-10 08:52:26.706665: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b9408f00 next 27 of size 256
2020-07-10 08:52:26.706668: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b9409000 next 28 of size 256
2020-07-10 08:52:26.706672: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b9409100 next 29 of size 2048
2020-07-10 08:52:26.706675: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b9409900 next 30 of size 16384
2020-07-10 08:52:26.706678: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b940d900 next 31 of size 2048
2020-07-10 08:52:26.706681: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b940e100 next 32 of size 256
2020-07-10 08:52:26.706685: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b940e200 next 33 of size 1280
2020-07-10 08:52:26.706688: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b940e700 next 35 of size 1024
2020-07-10 08:52:26.706691: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b940eb00 next 36 of size 1024
2020-07-10 08:52:26.706695: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f64b940ef00 next 18446744073709551615 of size 987392
2020-07-10 08:52:26.706698: I tensorflow/core/common_runtime/bfc_allocator.cc:914]      Summary of in-use Chunks by size:
2020-07-10 08:52:26.706703: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 26 Chunks of size 256 totalling 6.5KiB
2020-07-10 08:52:26.706707: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 4 Chunks of size 512 totalling 2.0KiB
2020-07-10 08:52:26.706711: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 6 Chunks of size 1024 totalling 6.0KiB
2020-07-10 08:52:26.706715: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 1280 totalling 1.2KiB
2020-07-10 08:52:26.706719: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 12 Chunks of size 2048 totalling 24.0KiB
2020-07-10 08:52:26.706723: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 4096 totalling 8.0KiB
2020-07-10 08:52:26.706726: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 6912 totalling 6.8KiB
2020-07-10 08:52:26.706730: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 4 Chunks of size 16384 totalling 64.0KiB
2020-07-10 08:52:26.706734: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 147456 totalling 144.0KiB
2020-07-10 08:52:26.706737: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 294912 totalling 288.0KiB
2020-07-10 08:52:26.706741: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 987392 totalling 964.2KiB
2020-07-10 08:52:26.706747: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 1179648 totalling 1.12MiB
2020-07-10 08:52:26.706754: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 2359296 totalling 4.50MiB
2020-07-10 08:52:26.706760: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 8432384 totalling 8.04MiB
2020-07-10 08:52:26.706767: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 3 Chunks of size 9437184 totalling 27.00MiB
2020-07-10 08:52:26.706772: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 16400384 totalling 15.64MiB
2020-07-10 08:52:26.706776: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 16777216 totalling 32.00MiB
2020-07-10 08:52:26.706779: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 28901376 totalling 55.12MiB
2020-07-10 08:52:26.706783: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 67108864 totalling 64.00MiB
2020-07-10 08:52:26.706787: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 536870912 totalling 512.00MiB
2020-07-10 08:52:26.706791: I tensorflow/core/common_runtime/bfc_allocator.cc:921] Sum Total of in-use chunks: 720.91MiB
2020-07-10 08:52:26.706795: I tensorflow/core/common_runtime/bfc_allocator.cc:923] total_region_allocated_bytes_: 1141899264 memory_limit_: 7421545677 available bytes: 6279646413 curr_region_allocation_bytes_: 8589934592
2020-07-10 08:52:26.706801: I tensorflow/core/common_runtime/bfc_allocator.cc:929] Stats:
Limit:                  7421545677
InUse:                   755930624
MaxInUse:               3647385856
NumAllocs:                     215
MaxAllocSize:           1641545728

2020-07-10 08:52:26.706809: W tensorflow/core/common_runtime/bfc_allocator.cc:424] **************_________________________________*************************************xxxxxxxxxx******
2020-07-10 08:52:26.706830: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at conv_ops.cc:500 : Resource exhausted: OOM when allocating tensor with shape[48,64,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.ResourceExhaustedError'>, 2 root error(s) found.
(0) Resource exhausted: OOM when allocating tensor with shape[48,64,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
[[node tower_0/v0/cg/conv0/conv2d/Conv2D (defined at /usr/lib/python3/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

(1) Resource exhausted: OOM when allocating tensor with shape[48,64,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
[[node tower_0/v0/cg/conv0/conv2d/Conv2D (defined at /usr/lib/python3/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

[[truediv_1/_83]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

0 successful operations.
0 derived errors ignored.

Original stack trace for 'tower_0/v0/cg/conv0/conv2d/Conv2D':
File "tf_cnn_benchmarks.py", line 73, in <module>
app.run(main)  # Raises error on invalid flags, unlike tf.app.run()
File "/usr/lib/python3/dist-packages/absl/app.py", line 299, in run
_run_main(main, args)
File "/usr/lib/python3/dist-packages/absl/app.py", line 250, in _run_main
sys.exit(main(argv))
File "tf_cnn_benchmarks.py", line 68, in main
bench.run()
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 1884, in run
return self._benchmark_train()
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 2080, in _benchmark_train
build_result = self._build_graph()
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 2112, in _build_graph
(input_producer_op, enqueue_ops, fetches) = self._build_model()
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 2832, in _build_model
gpu_compute_stage_ops, gpu_grad_stage_ops)
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 3352, in add_forward_pass_and_gradients
outputs = maybe_compile(forward_pass_and_gradients, self.params)
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 3549, in maybe_compile
return computation()
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 3206, in forward_pass_and_gradients
input_list, phase_train, nclass)
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/models/model.py", line 293, in build_network
self.add_inference(network)
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/models/vgg_model.py", line 74, in add_inference
_construct_vgg(cnn, [2, 2, 3, 3, 3])
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/models/vgg_model.py", line 38, in _construct_vgg
cnn.conv(64, 3, 3)
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py", line 184, in conv
kernel_initializer=kernel_initializer)
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py", line 134, in _conv2d_impl
use_bias=False)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/util/deprecation.py", line 324, in new_func
return func(*args, **kwargs)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/layers/convolutional.py", line 424, in conv2d
return layer.apply(inputs)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/util/deprecation.py", line 324, in new_func
return func(*args, **kwargs)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/keras/engine/base_layer.py", line 1700, in apply
return self.__call__(inputs, *args, **kwargs)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/layers/base.py", line 548, in __call__
outputs = super(Layer, self).__call__(inputs, *args, **kwargs)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/keras/engine/base_layer.py", line 854, in __call__
outputs = call_fn(cast_inputs, *args, **kwargs)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/autograph/impl/api.py", line 234, in wrapper
return converted_call(f, options, args, kwargs)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/autograph/impl/api.py", line 439, in converted_call
return _call_unconverted(f, args, kwargs, options)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/autograph/impl/api.py", line 330, in _call_unconverted
return f(*args, **kwargs)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/keras/layers/convolutional.py", line 197, in call
outputs = self._convolution_op(inputs, self.kernel)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/ops/nn_ops.py", line 1134, in __call__
return self.conv_op(inp, filter)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/ops/nn_ops.py", line 639, in __call__
return self.call(inp, filter)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/ops/nn_ops.py", line 238, in __call__
name=self.name)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/ops/nn_ops.py", line 2010, in conv2d
name=name)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py", line 1071, in conv2d
data_format=data_format, dilations=dilations, name=name)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/framework/op_def_library.py", line 794, in _apply_op_helper
op_def=op_def)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/util/deprecation.py", line 507, in new_func
return func(*args, **kwargs)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/framework/ops.py", line 3357, in create_op
attrs, op_def, compute_device)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/framework/ops.py", line 3426, in _create_op_internal
op_def=op_def)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/framework/ops.py", line 1748, in __init__
self._traceback = tf_stack.extract_stack()

I0710 08:52:26.719340 140074989942592 coordinator.py:224] Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.ResourceExhaustedError'>, 2 root error(s) found.
(0) Resource exhausted: OOM when allocating tensor with shape[48,64,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
[[node tower_0/v0/cg/conv0/conv2d/Conv2D (defined at /usr/lib/python3/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

(1) Resource exhausted: OOM when allocating tensor with shape[48,64,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
[[node tower_0/v0/cg/conv0/conv2d/Conv2D (defined at /usr/lib/python3/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

[[truediv_1/_83]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

0 successful operations.
0 derived errors ignored.

Original stack trace for 'tower_0/v0/cg/conv0/conv2d/Conv2D':
File "tf_cnn_benchmarks.py", line 73, in <module>
app.run(main)  # Raises error on invalid flags, unlike tf.app.run()
File "/usr/lib/python3/dist-packages/absl/app.py", line 299, in run
_run_main(main, args)
File "/usr/lib/python3/dist-packages/absl/app.py", line 250, in _run_main
sys.exit(main(argv))
File "tf_cnn_benchmarks.py", line 68, in main
bench.run()
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 1884, in run
return self._benchmark_train()
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 2080, in _benchmark_train
build_result = self._build_graph()
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 2112, in _build_graph
(input_producer_op, enqueue_ops, fetches) = self._build_model()
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 2832, in _build_model
gpu_compute_stage_ops, gpu_grad_stage_ops)
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 3352, in add_forward_pass_and_gradients
outputs = maybe_compile(forward_pass_and_gradients, self.params)
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 3549, in maybe_compile
return computation()
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 3206, in forward_pass_and_gradients
input_list, phase_train, nclass)
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/models/model.py", line 293, in build_network
self.add_inference(network)
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/models/vgg_model.py", line 74, in add_inference
_construct_vgg(cnn, [2, 2, 3, 3, 3])
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/models/vgg_model.py", line 38, in _construct_vgg
cnn.conv(64, 3, 3)
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py", line 184, in conv
kernel_initializer=kernel_initializer)
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py", line 134, in _conv2d_impl
use_bias=False)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/util/deprecation.py", line 324, in new_func
return func(*args, **kwargs)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/layers/convolutional.py", line 424, in conv2d
return layer.apply(inputs)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/util/deprecation.py", line 324, in new_func
return func(*args, **kwargs)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/keras/engine/base_layer.py", line 1700, in apply
return self.__call__(inputs, *args, **kwargs)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/layers/base.py", line 548, in __call__
outputs = super(Layer, self).__call__(inputs, *args, **kwargs)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/keras/engine/base_layer.py", line 854, in __call__
outputs = call_fn(cast_inputs, *args, **kwargs)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/autograph/impl/api.py", line 234, in wrapper
return converted_call(f, options, args, kwargs)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/autograph/impl/api.py", line 439, in converted_call
return _call_unconverted(f, args, kwargs, options)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/autograph/impl/api.py", line 330, in _call_unconverted
return f(*args, **kwargs)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/keras/layers/convolutional.py", line 197, in call
outputs = self._convolution_op(inputs, self.kernel)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/ops/nn_ops.py", line 1134, in __call__
return self.conv_op(inp, filter)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/ops/nn_ops.py", line 639, in __call__
return self.call(inp, filter)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/ops/nn_ops.py", line 238, in __call__
name=self.name)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/ops/nn_ops.py", line 2010, in conv2d
name=name)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py", line 1071, in conv2d
data_format=data_format, dilations=dilations, name=name)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/framework/op_def_library.py", line 794, in _apply_op_helper
op_def=op_def)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/util/deprecation.py", line 507, in new_func
return func(*args, **kwargs)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/framework/ops.py", line 3357, in create_op
attrs, op_def, compute_device)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/framework/ops.py", line 3426, in _create_op_internal
op_def=op_def)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/framework/ops.py", line 1748, in __init__
self._traceback = tf_stack.extract_stack()

Traceback (most recent call last):
File "/usr/lib/python3/dist-packages/tensorflow_core/python/client/session.py", line 1365, in _do_call
return fn(*args)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/client/session.py", line 1350, in _run_fn
target_list, run_metadata)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/client/session.py", line 1443, in _call_tf_sessionrun
run_metadata)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: 2 root error(s) found.
(0) Resource exhausted: OOM when allocating tensor with shape[48,64,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
[[{{node tower_0/v0/cg/conv0/conv2d/Conv2D}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

(1) Resource exhausted: OOM when allocating tensor with shape[48,64,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
[[{{node tower_0/v0/cg/conv0/conv2d/Conv2D}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

[[truediv_1/_83]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

0 successful operations.
0 derived errors ignored.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
File "tf_cnn_benchmarks.py", line 73, in <module>
app.run(main)  # Raises error on invalid flags, unlike tf.app.run()
File "/usr/lib/python3/dist-packages/absl/app.py", line 299, in run
_run_main(main, args)
File "/usr/lib/python3/dist-packages/absl/app.py", line 250, in _run_main
sys.exit(main(argv))
File "tf_cnn_benchmarks.py", line 68, in main
bench.run()
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 1884, in run
return self._benchmark_train()
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 2089, in _benchmark_train
return self._benchmark_graph(result_to_benchmark, eval_build_results)
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 2296, in _benchmark_graph
is_chief, summary_writer, profiler)
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 2434, in benchmark_with_session
is_chief))
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 871, in benchmark_one_step
results = sess.run(fetches, options=run_options, run_metadata=run_metadata)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/client/session.py", line 956, in run
run_metadata_ptr)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/client/session.py", line 1180, in _run
feed_dict_tensor, options, run_metadata)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/client/session.py", line 1359, in _do_run
run_metadata)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/client/session.py", line 1384, in _do_call
raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: 2 root error(s) found.
(0) Resource exhausted: OOM when allocating tensor with shape[48,64,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
[[node tower_0/v0/cg/conv0/conv2d/Conv2D (defined at /usr/lib/python3/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

(1) Resource exhausted: OOM when allocating tensor with shape[48,64,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
[[node tower_0/v0/cg/conv0/conv2d/Conv2D (defined at /usr/lib/python3/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

[[truediv_1/_83]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

0 successful operations.
0 derived errors ignored.

Original stack trace for 'tower_0/v0/cg/conv0/conv2d/Conv2D':
File "tf_cnn_benchmarks.py", line 73, in <module>
app.run(main)  # Raises error on invalid flags, unlike tf.app.run()
File "/usr/lib/python3/dist-packages/absl/app.py", line 299, in run
_run_main(main, args)
File "/usr/lib/python3/dist-packages/absl/app.py", line 250, in _run_main
sys.exit(main(argv))
File "tf_cnn_benchmarks.py", line 68, in main
bench.run()
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 1884, in run
return self._benchmark_train()
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 2080, in _benchmark_train
build_result = self._build_graph()
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 2112, in _build_graph
(input_producer_op, enqueue_ops, fetches) = self._build_model()
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 2832, in _build_model
gpu_compute_stage_ops, gpu_grad_stage_ops)
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 3352, in add_forward_pass_and_gradients
outputs = maybe_compile(forward_pass_and_gradients, self.params)
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 3549, in maybe_compile
return computation()
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 3206, in forward_pass_and_gradients
input_list, phase_train, nclass)
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/models/model.py", line 293, in build_network
self.add_inference(network)
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/models/vgg_model.py", line 74, in add_inference
_construct_vgg(cnn, [2, 2, 3, 3, 3])
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/models/vgg_model.py", line 38, in _construct_vgg
cnn.conv(64, 3, 3)
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py", line 184, in conv
kernel_initializer=kernel_initializer)
File "/home/ubuntu/lambda-tensorflow-benchmark/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py", line 134, in _conv2d_impl
use_bias=False)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/util/deprecation.py", line 324, in new_func
return func(*args, **kwargs)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/layers/convolutional.py", line 424, in conv2d
return layer.apply(inputs)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/util/deprecation.py", line 324, in new_func
return func(*args, **kwargs)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/keras/engine/base_layer.py", line 1700, in apply
return self.__call__(inputs, *args, **kwargs)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/layers/base.py", line 548, in __call__
outputs = super(Layer, self).__call__(inputs, *args, **kwargs)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/keras/engine/base_layer.py", line 854, in __call__
outputs = call_fn(cast_inputs, *args, **kwargs)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/autograph/impl/api.py", line 234, in wrapper
return converted_call(f, options, args, kwargs)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/autograph/impl/api.py", line 439, in converted_call
return _call_unconverted(f, args, kwargs, options)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/autograph/impl/api.py", line 330, in _call_unconverted
return f(*args, **kwargs)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/keras/layers/convolutional.py", line 197, in call
outputs = self._convolution_op(inputs, self.kernel)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/ops/nn_ops.py", line 1134, in __call__
return self.conv_op(inp, filter)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/ops/nn_ops.py", line 639, in __call__
return self.call(inp, filter)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/ops/nn_ops.py", line 238, in __call__
name=self.name)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/ops/nn_ops.py", line 2010, in conv2d
name=name)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py", line 1071, in conv2d
data_format=data_format, dilations=dilations, name=name)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/framework/op_def_library.py", line 794, in _apply_op_helper
op_def=op_def)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/util/deprecation.py", line 507, in new_func
return func(*args, **kwargs)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/framework/ops.py", line 3357, in create_op
attrs, op_def, compute_device)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/framework/ops.py", line 3426, in _create_op_internal
op_def=op_def)
File "/usr/lib/python3/dist-packages/tensorflow_core/python/framework/ops.py", line 1748, in __init__
self._traceback = tf_stack.extract_stack()

